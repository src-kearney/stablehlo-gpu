#loc = loc(unknown)
#loc1 = loc("x")
#loc2 = loc("bias")
module @jit_elementwise attributes {jax.uses_shape_polymorphism = false, mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main(%arg0: tensor<1x512x768xf32> loc("x"), %arg1: tensor<768xf32> loc("bias")) -> (tensor<1x512x768xf32> {jax.result_info = "result"}) {
    %0 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<768xf32>) -> tensor<1x1x768xf32> loc(#loc11)
    %1 = stablehlo.broadcast_in_dim %0, dims = [0, 1, 2] : (tensor<1x1x768xf32>) -> tensor<1x512x768xf32> loc(#loc12)
    %2 = stablehlo.add %arg0, %1 : tensor<1x512x768xf32> loc(#loc12)
    %3 = call @relu(%2) : (tensor<1x512x768xf32>) -> tensor<1x512x768xf32> loc(#loc13)
    return %3 : tensor<1x512x768xf32> loc(#loc)
  } loc(#loc)
  func.func private @relu(%arg0: tensor<1x512x768xf32> loc(unknown)) -> tensor<1x512x768xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32> loc(#loc16)
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<1x512x768xf32> loc(#loc15)
    %1 = stablehlo.maximum %arg0, %0 : tensor<1x512x768xf32> loc(#loc15)
    return %1 : tensor<1x512x768xf32> loc(#loc16)
  } loc(#loc16)
} loc(#loc)
#loc3 = loc("/Users/seanrck/github/stablehlo-gpu/explore/simple_attention_elementwise.py":9:23 to :31)
#loc4 = loc("/Users/seanrck/github/stablehlo-gpu/explore/simple_attention_elementwise.py":17:11 to :48)
#loc5 = loc("/Users/seanrck/github/stablehlo-gpu/explore/simple_attention_elementwise.py":9:11 to :32)
#loc6 = loc("elementwise"(#loc3))
#loc7 = loc("<module>"(#loc4))
#loc8 = loc("elementwise"(#loc5))
#loc9 = loc(callsite(#loc6 at #loc7))
#loc10 = loc(callsite(#loc8 at #loc7))
#loc11 = loc("jit(elementwise)/broadcast_in_dim"(#loc9))
#loc12 = loc("jit(elementwise)/add"(#loc9))
#loc13 = loc("jit(elementwise)/jit(relu)"(#loc10))
#loc14 = loc("jit"(#loc10))
#loc15 = loc("max"(#loc10))
#loc16 = loc("jit:"(#loc14))

